{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG8gJlo_3Ng6"
   },
   "source": [
    "For this assignment you will be working with the [Adult](https://archive.ics.uci.edu/dataset/2/adult) dataset from the UC Irvine Machine Learning Repository.\n",
    "\n",
    "This will be a pretty open ended assignment where you will have to apply the concepts you learned in the past few weeks towards building a model that can predict if an adult make less than or equal to or greater than $50,000 in annual income.\n",
    "\n",
    "There are 17 open ended questions, make sure to answer them!\n",
    "\n",
    "The folowing code will load the dataset into this notebook for you, make sure to read through the description of the dataset variables below:\n",
    "\n",
    "**Target Variable**:\n",
    "\n",
    "- Income: >50K, <=50K\n",
    "\n",
    "**Features**:\n",
    "- Age: `continuous`\n",
    "- Workclass: `Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked`\n",
    "- fnlwgt (Final Weight): `continuous`\n",
    "- Education: `Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool`\n",
    "- Education-num (Education Number): `continuous`\n",
    "- Marital-status: `Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse`\n",
    "- Occupation: `Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces`\n",
    "- Relationship: `Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried`\n",
    "- Race: `White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black`\n",
    "- Sex: `Female, Male`\n",
    "- Capital-gain: `continuous`\n",
    "- Capital-loss: `continuous`\n",
    "- Hours-per-week: `continuous`\n",
    "- Native-country: `United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoqLNkGL4Eo0",
    "outputId": "907ecd6f-a5b9-4d8b-db2c-b154b9f55062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.ustc.edu.cn/pypi/web/simple\n",
      "Requirement already satisfied: ucimlrepo in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from ucimlrepo) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from ucimlrepo) (2024.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jc4lf_A54FXA"
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ngCLoGax4IEX"
   },
   "outputs": [],
   "source": [
    "adult = fetch_ucirepo(id=2)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "x6KjOSyj4ixP",
    "outputId": "859b81c9-3bb3-4a45-a0ff-65c5a1272bd1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "      <th>type</th>\n",
       "      <th>demographic</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>Age</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workclass</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Income</td>\n",
       "      <td>Private, Self-emp-not-inc, Self-emp-inc, Feder...</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fnlwgt</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Education Level</td>\n",
       "      <td>Bachelors, Some-college, 11th, HS-grad, Prof-...</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>education-num</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>Education Level</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marital-status</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married-civ-spouse, Divorced, Never-married, S...</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>occupation</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Other</td>\n",
       "      <td>Tech-support, Craft-repair, Other-service, Sal...</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relationship</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Other</td>\n",
       "      <td>Wife, Own-child, Husband, Not-in-family, Other...</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Race</td>\n",
       "      <td>White, Asian-Pac-Islander, Amer-Indian-Eskimo,...</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Sex</td>\n",
       "      <td>Female, Male.</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>capital-loss</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hours-per-week</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Integer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>native-country</td>\n",
       "      <td>Feature</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Other</td>\n",
       "      <td>United-States, Cambodia, England, Puerto-Rico,...</td>\n",
       "      <td>None</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>income</td>\n",
       "      <td>Target</td>\n",
       "      <td>Binary</td>\n",
       "      <td>Income</td>\n",
       "      <td>&gt;50K, &lt;=50K.</td>\n",
       "      <td>None</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name     role         type      demographic  \\\n",
       "0              age  Feature      Integer              Age   \n",
       "1        workclass  Feature  Categorical           Income   \n",
       "2           fnlwgt  Feature      Integer             None   \n",
       "3        education  Feature  Categorical  Education Level   \n",
       "4    education-num  Feature      Integer  Education Level   \n",
       "5   marital-status  Feature  Categorical            Other   \n",
       "6       occupation  Feature  Categorical            Other   \n",
       "7     relationship  Feature  Categorical            Other   \n",
       "8             race  Feature  Categorical             Race   \n",
       "9              sex  Feature       Binary              Sex   \n",
       "10    capital-gain  Feature      Integer             None   \n",
       "11    capital-loss  Feature      Integer             None   \n",
       "12  hours-per-week  Feature      Integer             None   \n",
       "13  native-country  Feature  Categorical            Other   \n",
       "14          income   Target       Binary           Income   \n",
       "\n",
       "                                          description units missing_values  \n",
       "0                                                 N/A  None             no  \n",
       "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
       "2                                                None  None             no  \n",
       "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
       "4                                                None  None             no  \n",
       "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
       "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
       "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
       "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
       "9                                       Female, Male.  None             no  \n",
       "10                                               None  None             no  \n",
       "11                                               None  None             no  \n",
       "12                                               None  None             no  \n",
       "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
       "14                                       >50K, <=50K.  None             no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dfu7QSbG4NJQ"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income'] = df['income'].str.replace('.', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JGmMTTujFR3R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_jOyjvD6skf"
   },
   "source": [
    "The above code will load the dataset into the variable `df`. Now it's up to you to predict an Adult's income. Here are a few pointers and TODOs when approaching this problem. As you go through this assignment, make sure to look at the following and answer the questions **in this same maarkdown cell** you see here:\n",
    "\n",
    "1. **Does the data need to be cleaned?**\n",
    "   - Do some initial analysis, look at the data, and see if we need to use some pandas functions to reformat data cells (hint: you will have to do this, as this is somewhat of a messy dataset).\n",
    "   - Do we really need all the columns? Do a bit of research and ask questions in the discord to see if we need some of the columns in this dataset!\n",
    "     - ***Question 1: When do we actually drop a column?***\n",
    "     - Answer: A column should be dropped if it does not contribute significantly to the prediction of the target variable or if it contains redundant or irrelevant information, such as ID columns or constant columns.\n",
    "\n",
    "\n",
    "2. **Deal with missing values**\n",
    "   - A few columns have missing values; should you drop them? Impute these missing values as you see fit, such that the end model has good performance (note that this is a trial and error process as explained in class).\n",
    "   - There are several methods for this; look at the 10/30 class notebook.\n",
    "     - ***Question 2: Which methods of missing value imputation worked the best for you in the end? Do you think there is a specific reason why?***\n",
    "     - Answer: The best methods were imputing categorical features with the mode and numerical features with the mean. This worked well because these methods preserve the general data distribution and minimize information loss.\n",
    "\n",
    "3. **Encode the categorical data**\n",
    "   - There are several categorical features in this data. We discussed several ways of encoding these features and when to use some over the others, so use these methods to encode the data!\n",
    "     - ***Question 3: What is the difference between label encoding, one-hot encoding, and target encoding? For each one, list the pros and cons.***\n",
    "     - Answer: Label Encoding: Converts categories into integers (e.g., A=0, B=1).\n",
    "Pros: Simple and efficient for ordinal data.\n",
    "Cons: Can mislead models for non-ordinal data by introducing a false sense of order.\n",
    "One-Hot Encoding: Creates binary columns for each category.\n",
    "Pros: Removes ordinal relationships and works well for small categorical sets.\n",
    "Cons: Can create high-dimensional data if there are many categories.\n",
    "Target Encoding: Replaces categories with the mean of the target variable for each category.\n",
    "Pros: Handles high-cardinality features well.\n",
    "Cons: Risk of data leakage if not handled properly.\n",
    "     - ***Question 4: Do some research on your own; what are some other ways of encoding categorical data?***\n",
    "     - Answer: Binary Encoding: Encodes categories into binary digits.\n",
    "Frequency Encoding: Replaces categories with their frequency in the dataset.\n",
    "Hash Encoding: Uses hash functions to map categories to a fixed number of columns.\n",
    "\n",
    "4. **Split your data into a train and test dataset**\n",
    "   - When splitting your data into a train and test dataset, there are several parameters you have to pass in/consider (many of which can be optimized with a trial and error process):\n",
    "     - ***Question 5: What proportion of your dataset is the training dataset? Why did you choose this ratio?***\n",
    "     - Answer: 70% for training and 30% for testing. This provides sufficient data for model learning while keeping enough data to evaluate model performance.\n",
    "\n",
    "     - ***Question 6: Explain the difference between the train and test dataset. Why do we need them? Why can't we just train the model on the entire training dataset?***\n",
    "     - Answer: The train dataset is used to fit the model, while the test dataset evaluates its performance on unseen data. Training on the entire dataset would prevent us from knowing how well the model generalizes to new data.\n",
    "     - ***Question 7: Note that the dataset is very imbalanced. Why does this matter for splitting your dataset?***\n",
    "     - Answer: Imbalanced datasets can lead to biased models. Stratified splitting ensures the target class distribution remains consistent between the train and test datasets.\n",
    "\n",
    "5. **Scale your dataset**\n",
    "   - Note that when you scale your dataset, you fit & transform the training data and only transform the test data.\n",
    "     - ***Question 8: Why do you only fit to the training data and not the test data?***\n",
    "     - Answer: Fitting on the test data introduces data leakage, which inflates performance metrics and gives an unrealistic measure of how the model performs on new, unseen data.\n",
    "     - ***Question 9: In class, I talked about the standard scaler, but there are other methods (MinMax, Normalization, etc.). Do some research into a few other methods and explain each one. Make sure to mention when to use one over the other.***\n",
    "     - Answer: MinMax Scaler: Scales data to a range [0, 1]. Suitable when features have known bounds.\n",
    "Robust Scaler: Uses median and IQR, robust to outliers.\n",
    "Normalization: Scales data to unit norm (e.g., L2). Useful when working with distance-based algorithms.\n",
    "     - ***Question 10: What is the purpose of scaling your data in the first place?***\n",
    "     - Scaling ensures all features contribute equally to the model by normalizing their range, preventing features with larger ranges from dominating the model.\n",
    "\n",
    "6. **Modeling + Evaluation**\n",
    "   - For the assignment, make the following models to predict the binary \"income\" feature and output the accuracy, precision, recall, and F1 score, just use the default parameters:\n",
    "     - Linear Regression\n",
    "       - Note: Linear Regression does not make sense for this type of model, so make it so that any values above 0.5 are predicted as a 1 and 0 otherwise.\n",
    "       - ***Question 11: Why does linear regression not make sense to do here?***\n",
    "       - Answer: Linear regression assumes continuous target variables, whereas the target here is binary, making logistic regression more appropriate.\n",
    "     - Logistic Regression\n",
    "       - ***Question 12: Why does it make more sense to use logistic regression than linear?***\n",
    "       - Answer: Logistic regression models the probability of a binary outcome and outputs a value between 0 and 1, aligning with the binary classification task.\n",
    "     - Decision Trees\n",
    "     - Random Forest\n",
    "     - AdaBoost\n",
    "       - ***Question 13: We did not talk about AdaBoost in class, but do some research on this type of model and first explain how it works (briefly).***\n",
    "       - Answer: AdaBoost trains multiple weak learners (e.g., decision stumps) sequentially, with each learner focusing on the errors of the previous one. The final model combines all weak learners' predictions.\n",
    "       - ***Question 14: What is the idea of a stump?***\n",
    "       - Answer: A stump is a decision tree with a maximum depth of 1, typically used as a weak learner in ensemble methods like AdaBoost.\n",
    "       - ***Question 15: What is boosting and how does it apply to tree-based models?***\n",
    "       - Answer: Boosting is an ensemble technique that combines multiple weak learners to create a strong learner. In tree-based models, it iteratively adjusts sample weights to focus on harder-to-predict samples.\n",
    "\n",
    "7. **For the best model from step 6, use GridSearchCV and RandomSearchCV for tuning the model parameters; do some research into the hyperparameters:**\n",
    "   - ***Question 16: Which parameters did you choose to tune?***\n",
    "   - Answer: Parameters like n_estimators, max_depth, and min_samples_split were chosen as they have the most significant impact on tree-based model performance.\n",
    "\n",
    "   - ***Question 17: Did your GridSearch and RandomSearch output the same values for the hyperparameters? Why or why not?***\n",
    "   - Answer: No, GridSearch explores all possible parameter combinations, while RandomSearch samples a subset. Thus, results may differ due to the randomness in RandomSearch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data  Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XG2D0EUk9rt7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
      "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
      "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
      "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
      "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    48842.000000  \n",
      "mean        40.422382  \n",
      "std         12.391444  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n"
     ]
    }
   ],
   "source": [
    "# Do steps 1 - 7 here!\n",
    "\n",
    "# step 1\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "\n",
    "df.drop(columns=['fnlwgt'], inplace=True)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "df['workclass'] = df['workclass'].str.strip()\n",
    "df['occupation'] = df['occupation'].str.strip()\n",
    "df['native-country'] = df['native-country'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 0\n",
      "workclass         963\n",
      "education           0\n",
      "education-num       0\n",
      "marital-status      0\n",
      "occupation        966\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capital-gain        0\n",
      "capital-loss        0\n",
      "hours-per-week      0\n",
      "native-country    274\n",
      "income              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/k81dy6b535jcgmy6hdkj31v00000gn/T/ipykernel_66008/216026762.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['workclass'].fillna(df['workclass'].mode()[0], inplace=True)\n",
      "/var/folders/ws/k81dy6b535jcgmy6hdkj31v00000gn/T/ipykernel_66008/216026762.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['occupation'].fillna(df['occupation'].mode()[0], inplace=True)\n",
      "/var/folders/ws/k81dy6b535jcgmy6hdkj31v00000gn/T/ipykernel_66008/216026762.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['native-country'].fillna(df['native-country'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "df['workclass'].fillna(df['workclass'].mode()[0], inplace=True)\n",
    "df['occupation'].fillna(df['occupation'].mode()[0], inplace=True)\n",
    "df['native-country'].fillna(df['native-country'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "one_hot_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "df = pd.get_dummies(df, columns=one_hot_features, drop_first=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['income'] = label_encoder.fit_transform(df['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Accuracy: 0.8507\n",
      "Precision: 0.7312\n",
      "Recall: 0.5944\n",
      "F1 Score: 0.6558\n",
      "--- Decision Tree ---\n",
      "Accuracy: 0.8232\n",
      "Precision: 0.6337\n",
      "Recall: 0.6192\n",
      "F1 Score: 0.6264\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.8456\n",
      "Precision: 0.6999\n",
      "Recall: 0.6212\n",
      "F1 Score: 0.6582\n",
      "--- AdaBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/hetcom-llm/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8632\n",
      "Precision: 0.7735\n",
      "Recall: 0.6058\n",
      "F1 Score: 0.6795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='binary'):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average='binary'):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='binary'):.4f}\")\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (GridSearchCV): {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best parameters (RandomizedSearchCV): {'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_grid, cv=5, n_iter=10, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters (GridSearchCV):\", grid_search.best_params_)\n",
    "print(\"Best parameters (RandomizedSearchCV):\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
